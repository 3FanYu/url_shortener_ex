# Setting up the project

1. Make sure you've installed docker and docker-compose
2. Make sure you're in the root directory of the project
3. Run `make up` to start services
4. Run `make migrate` to run migrations
5. Run below command to test out the API, feel free to switch up the "url" with your favorite website
```
curl --location --request POST 'localhost:4000/api/url_mappings' \
--header 'Content-Type: application/json' \
--data-raw '{
    "url_mapping": {
        "original_url": "https://github.com/3FanYu/url_shortener_ex"
    }
}'
```
6. You should see return value as below
```
{"data":{"id":38,"short_url":"http://localhost:4000/1rWctT","original_url":"https://github.com/3FanYu/url_shortener_ex"}}%
```
7. Paste the `short_url` to your browser, and you should be redirected to your favorite website!


# API level design 
1. POST http://{host}/api/url_mappings
    - Param {string} url
    - Return short_url
2. GET http://{host}/{short_url}
    - Accept short_url
    - Redirect to original url if record found
    - Redirect to home page and flash an error if record not found


# Implementation 
## Shortening url:
- [x] Check if received url exists in DB, return directly if true.
- [x] Generate an unique ID using timestamp concat with the PID.
- [x] Use Base62 encode to generate short_url from unique ID.
- [x] Store the unique ID together with the original_url into cache.
- [x] Store the unique ID together with the original_url into database.
- [x] Return short url as a response to client
- [x] Each url is expired after 20 minutes, a Genserver is started to delete expired data periodically.


## Access original url using short url
- [x] Use Base62 decoding with the received short_url
- [x] Take the decoded result as the key to search in cache to get the original_url
- [x] Take the decoded result as the key to search in database to get the original_url
- [x] Response 302 and redirect client browser to original_url

## TODO
- Setup test environement and write test cases.

## Road Map

### About redirection
We have two kinds of http status code to choose from: 301 and 302. 301 means “move permanently”, it will make the client browser cache the redirection. 302 means “move temporarily”, which will not cache the redirection. In this case we will use 302 because we want the short url to expire, it would be difficult to test if the browser caches the redirection. However, in real life people might make decision based the usecase.

### How to ensure uniqueness of short url upon generating?
We can use timestamp in the form of milliseconds together with Base62 encoding to ensure the uniqueness of every ID.
Timestamp in seconds will have the length of 13 digits right now.
While timestamp looks great, there is still a chance when two requests were received at the exact same millisecond, and eventually lead to duplicate unique ID. To deal with that, we can concat the PID behind the timestamp:
EX: #PID<0.1721.0>
Merge the timestamp with the PID EX: 17070592948691721

Generating short urls
Hash functions like MD5 are generally fast and simple to implement. However there is always a possibility of collision, where two different inputs produces the same output.
Converting Base10 numbers to Base62 on the other hand, does not have collision risk of hash functions, as long as the encoded strings and of consistent length. Nevertheless, Base62 encoding & decoding can be slower than the hash functions. While performance issue is not significant in this usecase Try it out: https://math.tools/calculator/base/10-62
 For this project I will go with Base62 for the purpose of collision risk. 

### ID as the index key in DB
Now that we have short urls generated by unique_ids, we can store it into the database. We will be mapping a short url to its original url often, so my initial thought was to store short url as the index key, and map the url by querying: 
`select * from urls where short_url = <short_url>`
But as mentioned earlier, seting up index on integers will perform much better than string. Therefore we can store the unique_id as the index key instead. Everytime we receive request to map a short_url, we can decode the short_url back to its unique_id form, and query it like:
`select * from urls where short_url_id = <short_url_id>`

### Cache the mapping result
It’s not difficult to foresee the web app will be facing a lot of redirection request. Searching the short_url to original_url mapping directly from the database will get relatively expensive when facing high traffic, so it is better to cache the mapping result. There are many tools to choose from when it comes to memory caching, Redis is one of the no brainer that is used by many production services. But how should we cache it? One of the predictable behaviour of the user is to test the newly generated short url. Therefore we can cache the result into redis before even actually saving it into the database. In other cases, we can save the result of every redirect requests as a cache, however the TTL of each cache will be a very important factor if you don’t wish to store too much cache data when facing high traffic.


### Implementation 
Shortening url:
Check if received url exists in DB, return directly if true.
Generate an unique ID using timestamp concat with a counter
Use Base62 encode to generate short_url from unique ID.
Store the unique ID together with the original_url into cache and database.
Return short url as a response to client
Database collection will be set up with TTL index, so expired data will be deleted automatically.

Access original url using short url:
Use Base62 decoding with the received short_url
Take the decoded result as the key to search in cache or database to get the original_url
Response 302 and redirect client browser to original_url


### Go Beyond
Unfortunately, The implementation still faces some problems when we scale:
1. Heavy writes.

Regarding problem 2, we can implement the batch insertion mechanism, where we don’t directly write into the database. Instead, we will store the data inside of a cache and respond back to client directly after sending an event to a message queue. Later on the message queue will be pulled, then the data will eventually be inserted into the database. This way we won’t have to wait for database insertion before responding to our users.
